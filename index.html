
<!DOCTYPE html>
<html lang="en">
  <head>	  
    <!-- Global Site Tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-107224691-1"></script>
    <script>
       window.dataLayer = window.dataLayer || [];
       function gtag(){dataLayer.push(arguments)};
       gtag('js', new Date());

       gtag('config', 'UA-107224691-1');
    </script>

    <title>Xuehui Yu</title>
	  
    <!-- Credit to Reid Pryzant from Stanford for the website design... I largely plagiarized his work! -->

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
    <script type="text/javascript" src="https://use.fontawesome.com/981e0eb420.js"></script>
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css"/>
    <link href='https://fonts.googleapis.com/css?family=Lato:300,400,700,900%7COpen+Sans:400,600' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="./static/style.css" />

    <link rel="shortcut icon" href="./img/wi.ico" >
</head>


<body>
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
    	      <img src="img/9CB05386-6873-4809-A508-6679C1A4B69C_1_105_c.jpeg" alt="JPH :)" class="headshot" >
    	      <br/>
                    <h1>Xuehui Yu (于雪卉)
                        <small>
                            <a>yuxuehui0302@gmail.com </a> <span class="sep">|</span>
                            <span style="display: inline-block; white-space: nowrap;">
                                <a href="https://scholar.google.com/citations?user=mUZEUNoAAAAJ&amp;hl=en&amp;oi=ao/"><i class="fa fa-graduation-cap" aria-hidden="true"></i></a> <span class="sep"></span>|</span>
                                <a href="https://github.com/yuxuehui"><i class="fa fa-git"></i></a> <span class="sep">
                            </span>
                        </small>
                    </h1>
            </div>
        </div>
        <hr/>
        <div class="row">
            <div class="col-sm-2"><h5>About</h5></div>
            <div class="col-sm-10">
I am a Ph.D. student at Harbin Institute of Technology, affiliated with the <a href="http://wi.hit.edu.cn/" target="_blank" rel="nofollow">Web Intelligence Research Group</a>, under the mentorship of Professors <a href="https://scholar.google.com/citations?user=eApBCQYAAAAJ&hl=en" target="_blank" rel="nofollow">Yi Guan</a> and <a href="https://scholar.google.com/citations?user=mu6JYMAAAAAJ&hl=en" target="_blank" rel="nofollow">Jingchi Jiang</a>. Concurrently, I’m a visiting scholar in <a href="https://agents.inf.ed.ac.uk" target="_blank" rel="nofollow">Autonomous Agents Research Group</a> in the School of Informatics at the University of Edinburgh, advised by Professor <a herf="https://agents.inf.ed.ac.uk/stefano-albrecht" target="_blank" rel="nofollow">Stefano V. Albrecht</a>. I am primarily engaged in research on causal reinforcement learning, out-of-distribution generalization, and medical informatics, involving applications of intelligent control technologies and industrial implementation in fields such as smart healthcare and smart agriculture. 
</br></br>
My long-term research goal is to use RL to develop an autonomous intelligence system for the real world. I believe that good RL agents need to model how the world works first [<a href="https://pubmed.ncbi.nlm.nih.gov/35603381/" target="_blank" rel="nofollow">3</a>] [<a href="https://www.sciencedirect.com/science/article/pii/S0933365722001890" target="_blank" rel="nofollow">4</a>] and have strong generalization and robustness to deal with new challenges proposed by environments second [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417423006589" target="_blank" rel="nofollow">1</a>] [<a href="https://www.computer.org/csdl/proceedings-article/bibm/2022/09995255/1JC2lEoQeaY" target="_blank" rel="nofollow">2</a>] [<a href="" target="_blank" rel="nofollow">5</a>] [<a href="" target="_blank" rel="nofollow">7</a>].
</br></br>
In <font color="#189441"><strong>modeling how the world works</strong></font>, we have done two research: 
<ol>
    <li>The world model based on <b>cascading theory</b> [<a href="https://pubmed.ncbi.nlm.nih.gov/35603381/" target="_blank" rel="nofollow">3</a>] [<a href="https://www.sciencedirect.com/science/article/pii/S0933365722001890" target="_blank" rel="nofollow">4</a>], which models the physiological domino effect in environment dynamics. </li>
    <li> <b>Hidden-parameter block causal graph dynamics (Hip-BCGDs)</b>, which models environment dynamics with causal prompting from pre-trained models. </br>
    With the help of Hip-BCGDs, we proposed a novel model-based offline RL framework -- Causal Prompting Reinforcement Learning (CPRL) [<a href="" target="_blank" rel="nofollow">7</a>] , which is suitable for highly suboptimal and diverse offline datasets. CPRL is validated in simulation-based glucose-insulin systems and real-world offline datasets from Dnurse APP.
    </li>
</ol>

</br>
In <font color="#189441"><strong>decision making</strong></font>: 
<ol>
    <li> <b>Active RL:</b> A data-efficient and robust RL agent that can use real-time collected data to generalize in online testing quickly. We proposed a meta-RL framework -- Active Reinforcement Learning with Personalized Embeddings (ARLPE) [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417423006589" target="_blank" rel="nofollow">1</a>] [<a href="" target="_blank" rel="nofollow">5</a>].
    </li>
    <li> <b>Autonomous intelligence:</b> A hierarchical RL framework for self-supervised learning skills and reusing learned skills. We propose a Causal Coupled Mechanism (CCM) [<a href="https://www.computer.org/csdl/proceedings-article/bibm/2022/09995255/1JC2lEoQeaY" target="_blank" rel="nofollow">2</a>] to train a single policy to reuse skills and reach multiple goals instead of training policies for each task separately. CCM is validated in synthetic systems and a real-world biological regulatory system.
    </li>
</ol>

</br>
I am deploying autonomous intelligent decision models in a large-scale medical online system and real-world robots with the help of offline RL algorithms.

</br></br>

        </div>
        </div>
        <hr/>

        <!-- <div class="row">
            <div class="col-sm-2">
                <h5>News</h5>
            </div>
            <div class="col-sm-10">
          

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-12 columns">
                                <ul>
                                <li><b>[6/2022] </b> Our new work on <a href="https://arxiv.org/abs/2206.04779" target="_blank" rel="nofollow">offline RL from pixels</a> won an Outstanding Paper Award at <a href="https://sites.google.com/view/l-dod-rss2022" target="_blank" rel="nofollow">L-DOD</a>. 
                                </li>
                                </br> 
                                <li><b>[5/2022] </b> Two papers accepted to ICML 2022... see you in Baltimore :) 
                                </li>
                                </br> 
                                <li><b>[4/2022] </b> We are organizing the first workshop on Agent Learning in Open-Endedness at ICLR 2022, <a href="https://sites.google.com/view/aloe2022" target="_blank" rel="nofollow">come along</a>! 
                                </li>
                                </br> 
                                <li><b>[3/2022] </b> New work on multi-task RL was given an <a href="http://aistats.org/aistats2022/awards.html" target="_blank" rel="nofollow">honorable mention</a> for best paper at AISTATS!
                                </li>
                                </br> 
                                <li><b>[3/2022] </b> We released ACCEL, a new algorithm for open-ended learning, <a href="https://accelagent.github.io/" target="_blank" rel="nofollow">check it out</a>! 
                                </li>
                                </br> 
                                <li><b>[9/2021] </b> Three papers accepted to NeurIPS 2021! I'm grateful to work with such great people :) 
                                </li>
                                </br> 
                                <li><b>[6/2021]</b> I am interning at Facebook AI Research with Tim Rocktäschel and Ed Grefenstette. 
                                </li>
                                </br> 
                                <li><b>[11/2020]</b> PB2 was included into Ray Tune! Check out the <a href="https://www.anyscale.com/blog/population-based-bandits" target="_blank" rel="nofollow">blog post</a>. 
                                </li>
                                </br> 
                                <li><b>[9/2020]</b> Three papers accepted to NeurIPS 2020. Thank you to my amazing collaborators!! 
                                </li>
                                </br>  
                                <li><b>[6/2020]</b> Three papers accepted to the main conference at ICML 2020.
                                </li>
                                </li>
                                </br>                                  
                                <li><b>[2/2020]</b> New work on model-based RL, <i> Ready Policy One</i>, was covered by VentureBeat (<a href="https://venturebeat.com/2020/02/11/researchers-develop-technique-to-increase-sample-efficiency-in-reinforcement-learning/" target="_blank" rel="nofollow">here</a>). </li>
                                </ul>
                            </div>
                        </td>
                    </tr>
                </table> 
   
            </div>
            </div>
        <hr/> -->

        <div class="row">
            <div class="col-sm-2">
                <h5>Published Papers</h5>
            </div>
            <div class="col-sm-10">
                
                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/cvga.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>[1] ARLPE: A Meta Reinforcement Learning Framework for Glucose Regulation in Type 1 Diabetics </b>  </br> 
                                <b>Xuehui Yu</b>, Yi Guan, Lian Yan, Shulang Li, Xuelian Fu, Jingchi Jiang*.  </br> 
                                <i>Expert Systems With Applications, IF: 8.665. </i> </br>
                                <i><b>Keywords:</b> Artificial pancreas, automated insulin treatment, diabetes, meta reinforcement learning, active learning. </i> </br>
                                How to accomplish fast adaptation in the meta-testing period with limited interaction data? How to address the data distribution mismatch problem? Here are the tricks! :)  </br>
                                <a href="https://github.com/yuxuehui/arlpe" target="_blank" rel="nofollow">Open-source Code</a> / <a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417423006589" target="_blank" rel="nofollow">Paper</a></br>
                                <img src="img/teg-logo.png" style="vertical-align:middle;margin-right:10px" width="200"></br>
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>   

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/CCM.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>[2] Causal Coupled Mechanisms: A Control Method with Cooperation and Competition for Complex System </b>  </br> 
                                <b>Xuehui Yu</b>, Jingchi Jiang, Xinmiao Yu, Yi Guan*,Xue Li </br> 
                                <i>The (BIBM) 2022 IEEE International Conference on Bioinformatics and Biomedicine. </i> </br>
                                <i><b>Keywords:</b> complex system control, causal reasoning, hierarchical reinforcement learning. </i> </br>
                                We propose a novel hierarchical reinforcement learning framework for complex biological system control, which can self-supervised learn skills and reuse learned skills. </br>
                                <a href="https://www.computer.org/csdl/proceedings-article/bibm/2022/09995255/1JC2lEoQeaY" target="_blank" rel="nofollow">Paper</a></br>
                                <!-- (<a href="https://arxiv.org/abs/2203.01302" target="_blank" rel="nofollow">Paper</a>) (<a href="https://accelagent.github.io/" target="_blank" rel="nofollow">Website</a>) (<a href="https://www.youtube.com/watch?v=povBDxUn1VQ" target="_blank" rel="nofollow">Paper Review</a>) (<a href="https://www.youtube.com/watch?v=16BsJI5I-Yw&t=151s" target="_blank" rel="nofollow">Video Interview</a>)  -->
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/PerDF.png" width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>[3] PercolationDF: A percolation-based medical diagnosis framework</b>  </br> 
                                Jingchi Jiang, <b>Xuehui Yu</b>, Lin Y, Yi Guan*, et al. </br> 
                                <i> Mathematical Biosciences and Engineering, 2022, 19(6): 5832-5849. </i> </br>
                                <i><b>Keywords:</b> complex networks; knowledge representation; medical diagnosis; percolation theory</i></br>
                                <a href="https://pubmed.ncbi.nlm.nih.gov/35603381/" target="_blank" rel="nofollow">Paper</a></br>
                                <span><i><b>Partner: Xingyi People's Hospital </b></i></span>
                                <img src="img/xingyi_logo.png" style="vertical-align:middle;margin-right:10px" width="150"></br>
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/ICU.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>[4] DECAF: An Interpretable Deep Cascading Framework for ICU Mortality Prediction</b>  </br> 
                                Jingchi Jiang, <b>Xuehui Yu</b>, Boran Wang, Linjiang Ma, Yi Guan. </br> 
                                <i> Artificial Intelligence in Medicine (2022): 102437. </i> <font color=#189441> </br>
                                <a href="https://www.sciencedirect.com/science/article/pii/S0933365722001890" target="_blank" rel="nofollow">Paper</a>
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  


                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/vd4rl.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>[5] Contextual Policy Transfer in Meta-Reinforcement Learning via Active Learning </b>  </br> 
                                Jingchi Jiang, Lian Yan, <b>Xuehui Yu</b> and Yi Guan</br> 
                                <i>19th International Conference on Web Information Systems and Applications. </i> </br>
                                <a href="https://link.springer.com/chapter/10.1007/978-3-031-20309-1_31" target="_blank" rel="nofollow">Paper</a>  </br>
                                <!-- (<a href="https://arxiv.org/abs/2111.02994" target="_blank" rel="nofollow">Paper</a>) -->
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/nnn.jpg"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>[6] Unified Fine-Grained Biomedical Entity Recognition as a Combination of Boundary Detection and Sequence Generation</b>  </br> 
                                Xue Li, Yang Yang, Mingchen Ye, Yi Guan, <b>Xuehui Yu</b>, and Jingchi Jiang  </br> 
                                <a href="https://ieeexplore.ieee.org/document/9995683" target="_blank" rel="nofollow">Paper</a>  </br>
                                <i>The (BIBM) 2022 IEEE International Conference on Bioinformatics and Biomedicine. </i> </br>
                            </div>
                        </td>
                    </tr>
                </table> 
                </br></br>  

                               
            </div>
            </div>

            <hr/>  


        <div class="row">
            <div class="col-sm-2">
                <h5>Unpublished Papers</h5>
            </div>
            <div class="col-sm-10">    

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/pic2.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>[7] Causal Prompting Model-based Offline Reinforcement Learning </b>  </br> 
                                <b>Xuehui Yu</b>, Yi Guan, Rujia Shen, Chen Tang and Jingchi Jiang*.  </br> 
                                <i>International Conference on Autonomous Agents and Multiagent Systems 2023. Under Review. </i> </br>
                                <i><b>Keywords:</b> Reinforcement learning, Model-based offline reinforcement learning, Causal, Prompt.</i> </br>
                                How to complete the online deployment of offline RL agents in low-resource scenarios? A brave attempt in a medical large-scale online system! </br>
                                <font color="#189441"><strong>A medical benchmark is being built!</strong></font> A decision model can be trained in either supervised learning or offline reinforcement learning in the benchmark. </br>
                                <span><i><b>Partner: Beijing Dnurse Technology Company  </b></i></span>
                             <img src="img/dnurse_co.png" style="vertical-align:middle;margin-right:10px" width="90"></br>
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>  
            </div>
            </div>

            

            <hr/> 

        <div class="row">
            <div class="col-sm-2">
                <h5>Education</h5>
            </div>
            <div class="col-sm-10">
                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/HIT.jfif"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> Harbin Institute of Technology </b> - (2019-) </br> 
                                <i> I began my doctoral studies directly following my undergraduate degree, thanks to the postgraduate recommendation scheme. I am currently pursuing a PhD at the Faculty of Computing at Harbin Institute of Technology. </i>  </br> 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>                                                                                          

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/HEU.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> Harbin Engineering University </b> - (2015-2019) </br>
                                <i> I earned my bachelor’s degree in Internet of Things Engineering from the College of Computer Science and Technology, Harbin Engineering University in 2019. I was honoured the Outstanding Graduates in 2019. </i>   </br> 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>                                                                                          
            </div> 

        </div>

        <hr/>    
        <div class="row">
            <div class="col-sm-2">
                <h5>Additional Information</h5>
            </div>
            <div class="col-sm-10">
          
        
                <table class="borderless">
                    <tbody><tr>
                        <td>
                            <div class="large-12 columns">
                                <ul>
                                <li>
                                    Our <a href="http://59.110.228.72:10007/main" target="_blank" rel="nofollow">Chinese Medical Knowledge Graph</a>

                                </li>
                                <br> 
                                <li>Our <a href="http://39.105.117.206:10086/diet/main" target="_blank" rel="nofollow">Diabetic Diet Recommendation System</a> and a <a href="https://www.bilibili.com/video/av79645130/" target="_blank" rel="nofollow">demo video</a>.
                                <span><i><b>Our Partner: the Fourth Affiliated Hospital of Harbin Medical
                                    University  </b></i></span> 
                                <img src="img/yd4_logo.jpg" style="vertical-align:middle;margin-right:10px" width="150"></br>
                                </li>
                                <br> 
                                <li> For more core technologies, see <a href="http://wi.hit.edu.cn/hxjs.htm" target="_blank" rel="nofollow">WI Lab Homepage</a>
                                </li>
                                <br> 
                                </ul>
                            </div>
                        </td>
                    </tr>
                </tbody></table> 
        
            </div>
        </div>

        <hr/>
        


        <div class="footer">
	  <img  src="img/wi.jpg" alt="Robot" class="seal"></a>
      <a>yuxuehui0302@gmail.com </a> <span class="sep">|</span>
      <span style="display: inline-block; white-space: nowrap;">
          <a href="https://scholar.google.com/citations?user=mUZEUNoAAAAJ&amp;hl=en&amp;oi=ao/"><i class="fa fa-graduation-cap" aria-hidden="true"></i></a> <span class="sep"></span>|</span>
          <a href="https://github.com/yuxuehui"><i class="fa fa-git"></i></a> <span class="sep">
      </span>
	   <img src="img/think_out_of_box.png" style="float: right" alt="NA" class="seal"></a>
        </div>
    </div>
</br></br>


</body>

</html>
