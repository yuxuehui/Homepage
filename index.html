
<!DOCTYPE html>
<html lang="en">
  <head>	  
    <!-- Global Site Tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-107224691-1"></script>
    <script>
       window.dataLayer = window.dataLayer || [];
       function gtag(){dataLayer.push(arguments)};
       gtag('js', new Date());

       gtag('config', 'UA-107224691-1');
    </script>

    <title>Xuehui Yu</title>
	  
    <!-- Credit to Reid Pryzant from Stanford for the website design... I largely plagiarized his work! -->

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
    <script type="text/javascript" src="https://use.fontawesome.com/981e0eb420.js"></script>
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css"/>
    <link href='https://fonts.googleapis.com/css?family=Lato:300,400,700,900%7COpen+Sans:400,600' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="./static/style.css" />

    <link rel="shortcut icon" href="./img/favicon.ico" >
</head>


<body>
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
    	      <img src="img/9CB05386-6873-4809-A508-6679C1A4B69C_1_105_c.jpeg" alt="JPH :)" class="headshot" >
    	      <br/>
                    <h1>Xuehui Yu
                        <small>
                            <a>yuxuehui0302@gmail.com </a> <span class="sep">|</span>
                            <span style="display: inline-block; white-space: nowrap;">
                                <!-- <a href="mailto:yuxuehui0302@gmail.com"><i class="fa fa-envelope" aria-hidden="true"></i></a> <span class="sep"><span class="sep">|</span> -->
                                <a href="https://www.linkedin.com/in/yuxuehui"><i class="fa fa-linkedin" aria-hidden="true"></i></a><span class="sep"><span class="sep">|</span>
                                <a href="https://x.com/xuehui_yu"><i class="fa fa-twitter" aria-hidden="true"></i></a><span class="sep"><span class="sep">|</span>
                                <a href="https://scholar.google.com/citations?user=mUZEUNoAAAAJ&amp;hl=en&amp;oi=ao/"><i class="fa fa-graduation-cap" aria-hidden="true"></i></a><span class="sep"><span class="sep">|</span>
                                <a href="https://github.com/yuxuehui"><i class="fa fa-git"></i></a> <span class="sep">
                            </span>
                        </small>
                    </h1>
            </div>
        </div>
        <hr/>
        <div class="row">
            <div class="col-sm-2"><h5>About</h5></div>
            <div class="col-sm-10">
Hello &#128075 I am a final-year PhD student in the Language Technology Research Center, Faculty of Computing, Harbin Institute of Technology (HIT), co-supervised by Prof. <a href="https://scholar.google.com/citations?user=eApBCQYAAAAJ&hl=en" target="_blank" rel="nofollow">Yi Guan</a> and Prof. <a href="https://scholar.google.com/citations?user=mu6JYMAAAAAJ&hl=en" target="_blank" rel="nofollow">Jingchi Jiang</a>.
I was also a visiting PhD student in the <a href="https://agents-lab.org/" target="_blank" rel="nofollow">Autonomous Agents Research Group</a> at the University of Edinburgh (UoE), supervised by Prof. <a href="https://agents-lab.org/stefano-albrecht/" target="_blank" rel="nofollow">Stefano V. Albrecht</a>. </br> </br>

My research focuses on developing deep reinforcement learning (RL) algorithms for autonomous agents, with a particular focus on RL generalisation and causal RL. This journey deepened my interest in applying RL to build our robotic friends &#129302;, culminating in my favourite project [<a href="https://arxiv.org/pdf/2406.04815" target="_blank" rel="nofollow">1</a>] and inspiring me to dedicate my career to exploring this field further. </br> </br>
To enhance the generalisation ability of RL agents, my research explored several approaches: incentivising RL agents to self-correct and adapt within a single episode through meta-RL [<a href="https://arxiv.org/pdf/2406.04815" target="_blank" rel="nofollow">1</a>], encoding inductive biases via hierarchical reinforcement learning (HRL) [<a href="https://www.computer.org/csdl/proceedings-article/bibm/2022/09995255/1JC2lEoQeaY" target="_blank" rel="nofollow">3</a>], developing differentiable simulators [<a href="https://arxiv.org/pdf/2406.01065" target="_blank" rel="nofollow">a</a>] and addressing the real-to-sim gap through offline-to-online RL [b], enabling fast online adaptation through meta-RL [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417423006589" target="_blank" rel="nofollow">2</a>]. </br> 

In my first year, I was also involved in a project focused on disease diagnosis and spatio-temporal forecasting [<a href="https://pubmed.ncbi.nlm.nih.gov/35603381/" target="_blank" rel="nofollow">4</a>][<a href="https://www.sciencedirect.com/science/article/pii/S0933365722001890" target="_blank" rel="nofollow">5</a>].

<!-- During my Ph.D., I focused on RL generalisation and causal RL. To enable the deployment of RL-based healthcare agents in online settings, my research encompassed several key areas: learning dynamic model of disease evolution [<a href="https://pubmed.ncbi.nlm.nih.gov/35603381/" target="_blank" rel="nofollow">4</a>][<a href="https://www.sciencedirect.com/science/article/pii/S0933365722001890" target="_blank" rel="nofollow">5</a>], offline RL [<a href="https://www.computer.org/csdl/proceedings-article/bibm/2022/09995255/1JC2lEoQeaY" target="_blank" rel="nofollow">3</a>][<a href="https://arxiv.org/pdf/2406.01065" target="_blank" rel="nofollow">a</a>], offline-to-online RL [b], and meta-RL [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417423006589" target="_blank" rel="nofollow">2</a>], targeting generalisation problems in class-imbalanced offline data, cross-task shifts, online exploration, and fast online adaptation respectively.  </br> 
This journey deepened my interest in applying RL to build our robotic friends &#129302;, culminating in my favourite project [<a href="https://arxiv.org/pdf/2406.04815" target="_blank" rel="nofollow">1</a>] and inspiring me to dedicate my career to exploring this field further. -->
<!-- , which also shapes the direction of my future research aspirations &#10024; learning-based control method for general robots &#10024;  </br>  -->

        </div>
        </div>
        <hr/>

        <div class="row">
            <div class="col-sm-2"><h5>News</h5></div>
            <div class="col-sm-10">
                &#128226; 2024.9 &ensp; One paper accepted by &#128293; NeurIPS 2024 &#128293; </br>
                &#128226; 2024.8 &ensp; I have completed my one-year visit at the Autonomous Agents Research Group, and I’ve collected many precious memories in Edinburgh. All the best to my lovely friends and colleagues &#128149; </br>
                &#128226; 2024.6 &ensp; I am luck to organise an academic exchange for the Agent group to major institutions in China, including Tsinghua University, Peking University, and others. For more details, please see: <a href="https://x.com/s_albrecht/status/1798263203358794081" target="_blank" rel="nofollow"> Twitter </a> !! See you all there &#128075; </br> 
                &#128226; 2023.2 &ensp; I am delighted that my work [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417423006589" target="_blank" rel="nofollow">2</a>] [<a href="https://link.springer.com/chapter/10.1007/978-3-031-20309-1_31" target="_blank" rel="nofollow">6</a>] has been deployed in the WI Healthcare System, which is now serving doctors and patients in two hospitals &#x1F3E5;, as reported by <a href="https://www.hlj.chinanews.com.cn/hljnews/2023/0215/118648.html" target="_blank" rel="nofollow">WWW.CHINANEWS.COM</a> </br>
        </div>
        </div>
        <hr/>

        <div class="row">
            <div class="col-sm-2">
                <h5>Education</h5>
            </div>
            <div class="col-sm-10">
                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/UoE.svg.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> University of Edinburgh </b> - (2023-2024) </br> 
                                Project: Skill-aware Mutual Information Optimisation for Generalisation in Reinforcement Learning  </br> 
                                <i> I was a visiting student in the <a href="https://agents-lab.org/" target="_blank" rel="nofollow">Autonomous Agents Research Group</a> at the University of Edinburgh, supervised by Prof. <a href="https://agents-lab.org/stefano-albrecht/" target="_blank" rel="nofollow">Stefano V. Albrecht</a>.  </i>  </br> 
                            </div>
                        </td>
                    </tr>
                </table> 
                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/HIT.gif"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> Harbin Institute of Technology </b> - (2019-) </br> 
                                Thesis: Causal Reinforcement Learning Generalisation for Healthcare Agents </br> 
                                <i> I began my doctoral studies directly following my undergraduate degree, thanks to the postgraduate recommendation scheme. I am currently pursuing a PhD at the Faculty of Computing at Harbin Institute of Technology. </i>  </br>   
                                <i> GPA: 92.53/100   </i>  </br> 
                            </div>
                        </td>
                    </tr>
                </table> 
                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/work/HEU.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b> Harbin Engineering University </b> - (2015-2019) </br>
                                <i> I earned my bachelor’s degree in Internet of Things Engineering from the College of Computer Science and Technology, Harbin Engineering University in 2019. I was honoured the Outstanding Graduates and Outstanding Graduation Thesis in 2019.</i>  </br>   
                                <i> GPA: 88.95/100.  </i>  </br> 
                            </div>
                        </td>
                    </tr>
                </table> 

                </br></br>                                                                                          
            </div> 

        </div>

        <hr/>    

        <div class="row">
            <div class="col-sm-2">
                <h5>Selected Publication</h5>
            </div>
            <div class="col-sm-10">
                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/sami_thumbnail.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>[1] Skill-aware Mutual Information Optimisation for Generalisation in Reinforcement Learning </b>  </br> 
                                <b>Xuehui Yu</b>, Mhairi Dunion, Xin Li, Stefano V Albrecht  </br> 
                                <i><b><font color="#9900FF"> NeurIPS 2024 </font> </b>(poster) </i> </br>
                                <i>Keywords: contrastive learning, RL, meta RL, zero-shot generalisation.</i> </br>
                                &#10067; How to build general robots capable of seamlessly operating in any environment, with any object, and utilising various skills? 
                                With our SaMI learning objective, RL agents are incentivised to become versatile and zero-shot generalise across infinite tasks &#128521; </br>
                                &#128161; Generalisation starts with corrective behaviors. The ability to correct and try again is likely a key ingredient.</br>
                                <a href="https://github.com/uoe-agents/SaMI" target="_blank" rel="nofollow"> Code</a> <span class="sep">|</span> <a href="https://arxiv.org/pdf/2406.04815" target="_blank" rel="nofollow">Paper</a> <span class="sep">|</span> <a href="https://github.com/uoe-agents/Skill-aware-Panda-gym" target="_blank" rel="nofollow"> Our benchmark: Sa-Panda-gym</a> <span class="sep">|</span> <a href="https://recorder-v3.slideslive.com/?share=96779&s=cffc27e8-d386-41fb-8ab6-fe82a11990e3" target="_blank" rel="nofollow"> SlidesLive demo video </a> </br>
                            </div>
                        </td>
                    </tr>
                </table> 
                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/ARLPE.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>[2] ARLPE: A Meta Reinforcement Learning Framework for Glucose Regulation in Type 1 Diabetics </b>  </br> 
                                <b>Xuehui Yu</b>, Yi Guan, Lian Yan, Shulang Li, Xuelian Fu, Jingchi Jiang*  </br> 
                                <i>Expert Systems With Applications, IF: 8.665. </i> </br>
                                <i>Keywords: meta-RL, active learning, fast online adaptation, RL generalisation. </i> </br>
                                &#10067; How can rapid adaptation be achieved with extremely limited data in an online deployment? Employ “optimistic exploration” through active RL! </br>
                                &#128137; A RL-based closed-loop control method for artificial pancreas systems, enabling automatic medication infusion via pump control for diverse, previously unseen clinical patients.</br>
                                <a href="https://github.com/yuxuehui/arlpe" target="_blank" rel="nofollow"> Code</a> <span class="sep">|</span> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417423006589" target="_blank" rel="nofollow">Paper</a><span class="sep">|</span> <a href="https://apps.apple.com/cn/app/wi%E5%81%A5%E5%BA%B7%E7%AE%A1%E7%90%86/id6450258142" target="_blank" rel="nofollow">WI Healthcare APP</a></br>
                                <!-- <img src="img/teg-logo.png" style="vertical-align:middle;margin-right:10px" width="200"></br> -->
                            </div>
                        </td>
                    </tr>
                </table> 
                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/CCM.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>[3] Causal Coupled Mechanisms: A Control Method with Cooperation and Competition for Complex System </b>  </br> 
                                <b>Xuehui Yu</b>, Jingchi Jiang, Xinmiao Yu, Yi Guan*, Xue Li </br> 
                                <i>The (BIBM) 2022 IEEE International Conference on Bioinformatics and Biomedicine. </i> </br>
                                <i>Keywords: hierarchical RL, transfer learning, skill composition, RL generalisation. </i> </br>
                                &#128161; Using inductive biases to encourage or ensure the model does not rely on features that we expect to change: The policy should only rely on features which will behave similarly in both the training and testing environments.</br>
                                <a href="https://www.computer.org/csdl/proceedings-article/bibm/2022/09995255/1JC2lEoQeaY" target="_blank" rel="nofollow">Paper</a></br>
                                <!-- (<a href="https://arxiv.org/abs/2203.01302" target="_blank" rel="nofollow">Paper</a>) (<a href="https://accelagent.github.io/" target="_blank" rel="nofollow">Website</a>) (<a href="https://www.youtube.com/watch?v=povBDxUn1VQ" target="_blank" rel="nofollow">Paper Review</a>) (<a href="https://www.youtube.com/watch?v=16BsJI5I-Yw&t=151s" target="_blank" rel="nofollow">Video Interview</a>)  -->
                            </div>
                        </td>
                    </tr>
                </table> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/medical_diagnosis.png" width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>[4] PercolationDF: A percolation-based medical diagnosis framework</b>  </br> 
                                Jingchi Jiang, <b>Xuehui Yu</b>, Yi Lin, Yi Guan </br> 
                                <i> Mathematical Biosciences and Engineering, 2022, 19(6): 5832-5849. </i> </br>
                                <i>Keywords: medical diagnosis, knowledge representation.</i></br>
                                The dynamic model based on cascading theory, which models the physiological domino effect in environment dynamics; Increasing similarity between training and testing for generalisation in class-imbalanced datasets. </br> 
                                <a href="https://pubmed.ncbi.nlm.nih.gov/35603381/" target="_blank" rel="nofollow">Paper</a></br>
                                <!-- <span><i><b>Partner: Xingyi People's Hospital </b></i></span>
                                <img src="img/xingyi_logo.png" style="vertical-align:middle;margin-right:10px" width="150"></br> -->
                            </div>
                        </td>
                    </tr>
                </table> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/ICU.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>[5] DECAF: An Interpretable Deep Cascading Framework for ICU Mortality Prediction</b>  </br> 
                                Jingchi Jiang, <b>Xuehui Yu</b>, Boran Wang, Linjiang Ma, Yi Guan</br> 
                                <i> Artificial Intelligence in Medicine (2022): 102437. </i>  </br>
                                <i>Keywords: graph attention networks, spatio-temporal forecasting, interpretability, mortality prediction.</i></br>
                                The dynamic model based on cascading theory, which models the physiological domino effect in environment dynamics; Increasing similarity between training and testing for generalisation in class-imbalanced datasets.</br>
                                <a href="https://www.sciencedirect.com/science/article/pii/S0933365722001890" target="_blank" rel="nofollow">Paper</a>
                            </div>
                        </td>
                    </tr>
                </table> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/vd4rl.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>[6] Contextual Policy Transfer in Meta-Reinforcement Learning via Active Learning </b>  </br> 
                                Jingchi Jiang, Lian Yan, <b>Xuehui Yu</b> and Yi Guan</br> 
                                <i>19th International Conference on Web Information Systems and Applications. </i> </br>
                                <i>Keywords: meta-RL, active learning, fast online adaptation, RL generalisation. </i> </br>
                                <a href="https://link.springer.com/chapter/10.1007/978-3-031-20309-1_31" target="_blank" rel="nofollow">Paper</a>  </br>
                                <!-- (<a href="https://arxiv.org/abs/2111.02994" target="_blank" rel="nofollow">Paper</a>) -->
                            </div>
                        </td>
                    </tr>
                </table> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/nnn.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>[7] Unified Fine-Grained Biomedical Entity Recognition as a Combination of Boundary Detection and Sequence Generation</b>  </br> 
                                Xue Li, Yang Yang, Mingchen Ye, Yi Guan, <b>Xuehui Yu</b>, and Jingchi Jiang  </br> 
                                <i>The (BIBM) 2022 IEEE International Conference on Bioinformatics and Biomedicine. </i> </br>
                                <a href="https://ieeexplore.ieee.org/document/9995683" target="_blank" rel="nofollow">Paper</a>  </br>
                            </div>
                        </td>
                    </tr>
                </table> 

                <table class="borderless">
                    <tr>
                        <td>
                            <div class="large-1 columns">
                                    <img src="img/pubs/ARLPE.png"  width="100">
                            </div>
                        </td>
                        <td>
                            <div class="large-12 columns", style="margin: 20px">
                                <b>[8] An interactive food recommendation system using reinforcement learning</b>  </br> 
                                Liangliang Liu, Yi Guan, Zi Wang, Rujia Shen, Guowei Zheng, Xuelian Fu, <b>Xuehui Yu</b>, Jingchi Jiang</br> 
                                <i> Expert Systems With Applications, IF: 8.665. </i> </br>
                                <i>Keywords: food recommender systems, RL, collaborative filtering, cross attention, state representation</i></br>
                                <a href="https://www.sciencedirect.com/science/article/pii/S0957417424011795" target="_blank" rel="nofollow">Paper</a><span class="sep">|</span> <a href="https://apps.apple.com/cn/app/wi%E5%81%A5%E5%BA%B7%E7%AE%A1%E7%90%86/id6450258142" target="_blank" rel="nofollow">WI Healthcare APP</a>  </br>
                            </div>
                        </td>
                    </tr>
                </table> 

            </div>
            </div>

            <hr/>  

            <div class="row">
                <div class="col-sm-2">
                    <h5>Preprints</h5>
                </div>
                <div class="col-sm-10">    
    
    
                    <table class="borderless">
                        <tr>
                            <td>
                                <div class="large-1 columns">
                                        <img src="img/pubs/pic2.png"  width="100">
                                </div>
                            </td>
                            <td>
                                <div class="large-12 columns", style="margin: 20px">
                                    <b>[a] Causal Prompting Model-based Offline Reinforcement Learning </b>  </br> 
                                    <b>Xuehui Yu</b>, Yi Guan, Rujia Shen, Chen Tang, Jingchi Jiang*  </br> 
                                    <!-- <i>IEEE Transactions on Neural Networks and Learning Systems. Under Review. </i> </br> -->
                                    <i>Keywords: differentiable and scalable simulators, model-based offline RL, causal RL, RL generalisation.</i> </br>
                                    &#128161; A simulation good enough for useful evaluation signal may be much easier to build than a full digital clone for training. </br>
                                    &#128208; Building better simulators doesn’t necessarily mean they must be entirely realistic; the key is to focus on the sim-to-real gap and differentials have smaller sim-to-real gap.</br>
                                    &#128165; <a href="https://github.com/yuxuehui/VirtualPatient" target="_blank" rel="nofollow">VirtualPatient</a> is designed to be fully compatible with differentiable simulation. </br>
                                    <a href="https://arxiv.org/pdf/2406.01065" target="_blank" rel="nofollow">Paper</a> </br> 
                                    <!-- <span><i><b>Partner: Beijing Dnurse Technology Company  </b></i></span>
                                    <img src="img/dnurse_co.png" style="vertical-align:middle;margin-right:10px" width="90"></br> -->
                                </div>
                            </td>
                        </tr>
                    </table> 

                    <table class="borderless">
                        <tr>
                            <td>
                                <div class="large-1 columns">
                                        <img src="img/pubs/o2o.png"  width="100">
                                </div>
                            </td>
                            <td>
                                <div class="large-12 columns", style="margin: 20px">
                                    <b>[b] KaDGT: How to Survive in Online Personalisation with Highly Low-quality Offline Datasets </b>  </br> 
                                    <b>Xuehui Yu</b>, Rujia Shen, Yanming Li, Chen Tang, Yi Guan*  </br> 
                                    <i>Keywords: real-to-sim, offline-to-online RL, Transformer-based RL, RL generalisation.</i> </br>
                                    &#10067; Can the pretraining (offline) + finetuning (online) paradigm, remarkably successful in language and vision, also be successful in RL? Improve upon the offline performance using very few online data. </br>
                                    &#128161; Balancing the “Improvement-Constraint” trade-off through knowledge encoding enables sample-efficient online exploration. </br>
                                </div>
                            </td>
                        </tr>
                    </table> 
                    
                </div>
                </div>
                <hr/> 

        <div class="row">
            <div class="col-sm-2"><h5>Awards & Honours </h5></div>
            <div class="col-sm-10">
                <ul>
                <li><b>2023 World’s Top Universities Strategic Cooperation Fellowship Initiative</b></li>
                <li><b>2023 and 2019 Heilongjiang Province Merit Student</b></li>
                <li><b>2018 National Scholarship</b></li>
                    <ul>
                        <li>Awarded to 140 students school-wide in 2018, about 1% </li>
                    </ul>
                <li><b>2018 Pacemaker to Merit Student</b> 
                    <ul>
                        <li>Only 10 selected school-wide each year </li>
                    </ul>
                </li>
                <li><b>2017 China Undergraduate Mathematical Contest in Modeling, National Second Prize</b>;</br>
                    <ul>
                    <li>Problem A: <i>CT System Parameter Calibration and Imaging</i> </li>
                    <li>Addressed calibration challenges in CT systems, where installation errors impact imaging quality. </li>
                    <li>Developed methods to calibrate system parameters using known structured samples (templates) and applied these parameters to image unknown samples.</li>
                    </ul>
                </li>
                <li><b>2017 Northeast Three Provinces Mathematical Contest in Modeling, Provincial Third Prize</b></li>
                <li><b>14th 'Bochuang Cup' National College Student Embedded System Design Contest, Provincial Third Prize</b> 
                    <ul>
                    <li>Project: <i>Kindergarten Safety Protection System</i> </li>
                    <li>Developed a system leveraging multiple sensors to monitor children’s activities, detect unusual behaviours, and identify potential risks. </li>
                    <li>Enabled timely alerts to caregivers and teachers, facilitating swift responses and creating a safer environment for children.</li>
                    </ul>
                </li>
                <li><b>Heilongjiang Province 5th College Students Art Performance, Vocal Music Category A, Third Prize</b> &#127926; </li>
                </ul>
        </div>
        </div>
        <hr/>

        <div class="row">
            <div class="col-sm-2">
                <h5>Additional Information</h5>
            </div>
            <div class="col-sm-10">
          
        
                <table class="borderless">
                    <tbody><tr>
                        <td>
                            <div class="large-12 columns">
                                <ul>
                                    <li>
                                        In life, I &#127934; &#127938; &#127947; &#127939;   
                                        I am a core member of the tennis association at HIT &#128569; 
                                        I used to be a member of the HaiZhiYun Choir &#127926; and the QiDian Art Studio &#127912;
                                        </li>
                                    <li>
                                        &#127775; <b> Part of my memorable moment at UoE </b> &#127775; <a href="https://sites.google.com/view/icvs-2024/home-page" target="_blank" rel="nofollow">1st International Conference for Visiting Students </a> &#127891; &#x1F1EC;&#x1F1E7; 
                                    </li>
                                <!-- <img src="img/yd4_logo.jpg" style="vertical-align:middle;margin-right:10px" width="150"></br> -->
                                </li>
                                </ul>
                            </div>
                        </td>
                    </tr>
                </tbody></table> 
        
            </div>
        </div>

        <hr/>
        


        <div class="footer">
      <!-- <a>yuxuehui0302@gmail.com </a> <span class="sep">|</span> -->
      <span style="display: inline-block; white-space: nowrap;">
          <a href="mailto:yuxuehui0302@gmail.com"><i class="fa fa-envelope" aria-hidden="true"></i></a> <span class="sep"><span class="sep">|</span>
          <a href="https://www.linkedin.com/in/yuxuehui"><i class="fa fa-linkedin" aria-hidden="true"></i></a><span class="sep"><span class="sep">|</span>
          <a href="https://x.com/xuehui_yu"><i class="fa fa-twitter" aria-hidden="true"></i></a><span class="sep"><span class="sep">|</span>
          <a href="https://scholar.google.com/citations?user=mUZEUNoAAAAJ&amp;hl=en&amp;oi=ao/"><i class="fa fa-graduation-cap" aria-hidden="true"></i></a><span class="sep"><span class="sep">|</span>
          <a href="https://github.com/yuxuehui"><i class="fa fa-git"></i></a> <span class="sep">
      </span>
        </div>
    </div>
</br></br>


</body>

</html>
